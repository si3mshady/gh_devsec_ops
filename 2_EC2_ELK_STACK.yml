AWSTemplateFormatVersion: 2010-09-09

Parameters:
  Environment:
    Type: String

  StackName:
    Type: String

Conditions:
  IsDevEnvironment: !Equals [!Ref Environment, "dev"]

Resources:
  SecurityGroupGrafanaProm:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Allow access to Prometheus and Grafana.
      Tags:
        - Key: Name
          Value: !Join ['-', ['SecurityGroupGrafanaProm', !Ref Environment]]
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 3000
          ToPort: 3000
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          FromPort: 22
          ToPort: 22
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          FromPort: 9090
          ToPort: 9090
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          FromPort: 5000
          ToPort: 5000
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          FromPort: 5601
          ToPort: 5601
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          FromPort: 9200
          ToPort: 9200
          CidrIp: 0.0.0.0/0

  ElasticIpELK:
    Type: AWS::EC2::EIP
    Properties:
      Domain: vpc

  EC2InstancePrometheusGrafana:
    Type: AWS::EC2::Instance
    Properties:
      ImageId: !If
        - IsDevEnvironment
        - ami-0a695f0d95cefc163  # AMI ID for 'dev' environment
        - ami-007855ac798b5175e  # AMI ID for 'prod' environment
      InstanceType: t2.large
      KeyName: turnthepage
      SecurityGroupIds:
        - !Ref SecurityGroupGrafanaProm
      Tags:
        - Key: Name
          Value: !Join ['-', ['PrometheusAndGrafana-bluegreen-', !Ref Environment]]
      UserData:
        Fn::Base64: !Sub |
          #!/bin/bash
          # Install wget and Filebeat
          sudo yum install wget -y
          wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.15.2-amd64.rpm
          sudo rpm -vi filebeat-7.15.2-amd64.rpm




          # Download prom_install, grafana_install, and log_generator.py
          wget https://raw.githubusercontent.com/si3mshady/gh_devsec_ops/main/prom_install.sh
          wget https://raw.githubusercontent.com/si3mshady/gh_devsec_ops/main/grafana_install.sh
          wget https://raw.githubusercontent.com/si3mshady/gh_devsec_ops/main/log_generator.py

          # Make prom_install and grafana_install executable
          chmod +x prom_install.sh
          chmod +x grafana_install.sh

          # Run prom_install
          ./prom_install.sh
          # Run grafana_install
          ./grafana_install.sh

          # Configure Filebeat
          sudo tee /etc/filebeat/filebeat.yml > /dev/null <<EOF
          filebeat.inputs:
          - type: log
            paths:
              - ./logs.log  # Replace with the actual path to the log file

          output.elasticsearch:
            hosts: ["${ElasticIpELK.PublicIp}:9200"]  # Replace with the Elasticsearch host and port

          EOF

          # Start and enable Filebeat service
          sudo systemctl start filebeat
          sudo systemctl enable filebeat

          # Run the log generator script
          sudo yum install python3
          python3 --version > python3.txt
          pip3 --version > pip3.txt
          pip3 install -r requirements.txt

          python3 log_generator.py



#new 
  EC2InstanceELK:
    Type: AWS::EC2::Instance
    Properties:
      ImageId: !If
        - IsDevEnvironment
        - ami-0a695f0d95cefc163  # AMI ID for 'dev' environment
        - ami-053b0d53c279acc90 # AMI ID for 'prod' environment
      InstanceType: m5.large 
      KeyName: turnthepage
      BlockDeviceMappings:
      - DeviceName: /dev/sda1
        Ebs:
          VolumeSize: 100
          VolumeType: gp2
      SecurityGroupIds:
        - !Ref SecurityGroupGrafanaProm
      Tags:
        - Key: Name
          Value: !Join ['-', ['ELK-', !Ref Environment]]
      UserData:
        Fn::Base64: !Sub |
          #!/bin/bash

          # Install Docker Compose
          sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
          sudo chmod +x /usr/local/bin/docker-compose

          # Install Docker
          sudo apt-get update
          sudo apt-get install -y apt-transport-https ca-certificates curl software-properties-common
          curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
          echo "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
          sudo apt-get update
          sudo apt-get install -y docker-ce docker-ce-cli containerd.io

          # Start Docker service
          sudo systemctl start docker
          sudo systemctl enable docker

          # Create a directory for the Docker Compose file
          mkdir my-elk-stack
          cd my-elk-stack

          # sudo apt install python3 python3-pip -y

          # # Create the Logstash configuration file
          # echo 'input {
          #   file {
          #     path => "/logstash_dir/logs.log"
          #     start_position => "beginning"
          #   }
          # }

          # output {
          #   elasticsearch {
          #     hosts => ["elasticsearch:9200"]
          #     index => "elliott_arnold_linkedin-%{+YYYY.MM.dd}"
          #   }
          # }' > ./logstash.conf


          # # sleep 3


          # Create the Docker Compose file
          echo 'version: "3.7"

          services:
            elasticsearch:
              image: docker.elastic.co/elasticsearch/elasticsearch:8.7.1
              container_name: elasticsearch
              restart: always
              volumes:
                - es_data:/usr/share/elasticsearch/data
              environment:
                - discovery.type=single-node
                - ES_JAVA_OPTS=-Xmx1g
              ports:
                - 9200:9200
                - 9300:9300
              networks:
                - elk_network

            logstash:
              image: docker.elastic.co/logstash/logstash:8.7.1
              depends_on:
                - elasticsearch
              container_name: logstash
              restart: always
              environment:
                - LS_JAVA_OPTS=-Xmx1g
                - LS_OPTS=--path.settings=/usr/share/logstash/config
              ports:
                - 9600:9600
              command: logstash -f /logstash_dir/logstash.conf
              volumes:
                - ./mount:/logstash_dir/logstash.conf
                - ./mount/:/logstash_dir/logs.log
              networks:
                - elk_network


            kibana:
              image: docker.elastic.co/kibana/kibana:8.7.1
              depends_on:
                - elasticsearch
              container_name: kibana
              restart: always
              environment:
                - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
              ports:
                - 5601:5601
              networks:
                - elk_network

          volumes:
            es_data:

          networks:
            elk_network:
              driver: bridge' > docker-compose.yml

          # Start the ELK stack using Docker Compose
          sudo docker-compose up && \
          sudo docker exec -it elasticsearch sed -i 's/true/false/g' /usr/share/elasticsearch/config/elasticsearch.yml && \
          sudo docker restart elasticsearch && \
          sudo docker restart  logstash && \
          sudo docker restart  kibana


Outputs:
  PublicDnsName:
    Value: !GetAtt ElasticIpELK.PublicIp



# sudo docker exec -it elasticsearch sed -i 's/true/false/g' /usr/share/elasticsearch/config/elasticsearch.yml

# docker exec -it elasticsearch sed -i 's/old_text/new_text/g' /path/to/file

    #  sudo less /var/log/cloud-init-output.log
# Save the script to a file (e.g., install_elk.sh), make it executable using the command chmod +x install_elk.sh, and then execute it with ./install_elk.sh.

# This script performs the following steps:

# Updates the system packages.
# Installs the Java Runtime Environment (JRE).
# Downloads and installs Elasticsearch.
# Enables and starts the Elasticsearch service.
# Installs Logstash.
# Enables and starts the Logstash service.
# Installs Kibana.
# Enables and starts the Kibana service.
# After running this script, the ELK stack should be installed and running on your Ubuntu system. You can access Kibana by visiting http://localhost:5601 in your web browser.